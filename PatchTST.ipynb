{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1lRaq41ULsrk24k5ZIMNXQ-Et31SaE1VM",
      "authorship_tag": "ABX9TyOQSmfZaCd1bmonEvXWdm8s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsidaarth/Transformer-Variants-for-HourvAhead-PV-Forecasting/blob/main/PatchTST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aaNU7zGGn2a",
        "outputId": "0c7f7205-5e06-445c-8797-136802d49147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7B0jbmhFsxM"
      },
      "outputs": [],
      "source": [
        "import importlib.util\n",
        "import sys\n",
        "\n",
        "# Add PatchTST_supervised to Python path\n",
        "sys.path.append('/content/drive/MyDrive/PatchTST/PatchTST_supervised')\n",
        "\n",
        "# Load PatchTST model\n",
        "patchtst_path = \"/content/drive/MyDrive/PatchTST/PatchTST_supervised/models/PatchTST.py\"\n",
        "spec = importlib.util.spec_from_file_location(\"patchtst_model\", patchtst_path)\n",
        "patchtst_module = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"patchtst_model\"] = patchtst_module\n",
        "spec.loader.exec_module(patchtst_module)\n",
        "\n",
        "# Access model class\n",
        "PatchTST = patchtst_module.Model\n",
        "\n",
        "# Load PatchTST_backbone\n",
        "backbone_path = \"/content/drive/MyDrive/PatchTST/PatchTST_supervised/layers/PatchTST_backbone.py\"\n",
        "spec_backbone = importlib.util.spec_from_file_location(\"patchtst_backbone\", backbone_path)\n",
        "backbone_module = importlib.util.module_from_spec(spec_backbone)\n",
        "sys.modules[\"patchtst_backbone\"] = backbone_module\n",
        "spec_backbone.loader.exec_module(backbone_module)\n",
        "\n",
        "# Access PatchTST_backbone\n",
        "PatchTST_backbone = backbone_module.PatchTST_backbone\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "aRbnk4qCGeJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "df = pd.read_csv('/content/updated_timetable.txt')\n",
        "df.columns=['datetime','irradiation_forecast','temperature_forecast','irradiation','temperature','power']\n",
        "tdi = pd.to_datetime(df['datetime'], format='%d-%m-%y %H')\n",
        "df.set_index(tdi, inplace=True)\n",
        "\n",
        "# # Define date ranges to remove\n",
        "# ranges_to_remove = [\n",
        "#     ('2018-05-01', '2018-05-22'),\n",
        "#     ('2019-09-09', '2019-09-28'),\n",
        "#     ('2019-11-29', '2020-01-20'),\n",
        "#     ('2013-07-23', '2013-08-26')\n",
        "# ]\n",
        "\n",
        "# # Create a boolean mask for rows to keep\n",
        "# mask = pd.Series(True, index=df.index)\n",
        "# for start, end in ranges_to_remove:\n",
        "#     mask &= ~((df.index >= start) & (df.index <= end))\n",
        "\n",
        "# # Apply the mask to the DataFrame\n",
        "# data = df[mask]\n",
        "start_date = '2014-01-01'\n",
        "end_date = '2019-01-31'\n",
        "# Filter the data for the specified date range\n",
        "data = df[start_date:end_date]\n",
        "\n",
        "data = data.drop(columns=['datetime','irradiation_forecast','temperature_forecast'])\n",
        "data['power'] = data['power']/1000\n",
        "\n",
        "# data['power'] = data['power']/data['power'].max()*317\n",
        "# data = data[59905::]"
      ],
      "metadata": {
        "id": "BwTkWBsaGJYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # === Descriptive audit for PV dataset (train vs last-12-month test) ===\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# # Ensure expected columns & index\n",
        "# assert isinstance(data.index, pd.DatetimeIndex), \"data must have a DatetimeIndex\"\n",
        "# expected_cols = [\"irradiation\", \"temperature\", \"power\"]\n",
        "# missing_cols = [c for c in expected_cols if c not in data.columns]\n",
        "# assert not missing_cols, f\"Missing columns in data: {missing_cols}\"\n",
        "\n",
        "# # Define split (last 12 months from end_date)\n",
        "# end_date_pd = pd.to_datetime(\"2019-01-31\")\n",
        "# test_start = end_date_pd - pd.DateOffset(months=12)\n",
        "\n",
        "# train = data[:test_start]\n",
        "# test  = data[test_start:]\n",
        "\n",
        "# def basic_stats(df):\n",
        "#     out = df.agg(['count','mean','std','min','median','max']).T\n",
        "#     # % of zeros (useful for PV)\n",
        "#     out['pct_zero'] = (df.eq(0).sum() / df.shape[0] * 100).values\n",
        "#     # NaNs\n",
        "#     out['n_nan'] = df.isna().sum().values\n",
        "#     return out\n",
        "\n",
        "# def drift_summary(train_s, test_s, name):\n",
        "#     mu_tr, mu_te = train_s.mean(), test_s.mean()\n",
        "#     sd_tr, sd_te = train_s.std(ddof=0), test_s.std(ddof=0)\n",
        "#     return {\n",
        "#         \"var\": name,\n",
        "#         \"mean_train\": float(mu_tr), \"mean_test\": float(mu_te),\n",
        "#         \"mean_shift_%\": float((mu_te - mu_tr) / (abs(mu_tr) + 1e-12) * 100),\n",
        "#         \"std_train\": float(sd_tr), \"std_test\": float(sd_te),\n",
        "#         \"std_shift_%\": float((sd_te - sd_tr) / (sd_tr + 1e-12) * 100),\n",
        "#     }\n",
        "\n",
        "# # Global info\n",
        "# print(\"=== Coverage ===\")\n",
        "# print(f\"Full range: {data.index.min().date()} → {data.index.max().date()} \"\n",
        "#       f\"({data.shape[0]} rows)\")\n",
        "# print(f\"Train:      {train.index.min().date()} → {train.index.max().date()} \"\n",
        "#       f\"({train.shape[0]} rows)\")\n",
        "# print(f\"Test:       {test.index.min().date()}  → {test.index.max().date()}  \"\n",
        "#       f\"({test.shape[0]} rows)\")\n",
        "# try:\n",
        "#     print(\"Inferred frequency:\", pd.infer_freq(data.index))\n",
        "# except Exception:\n",
        "#     print(\"Inferred frequency: <unable to infer>\")\n",
        "\n",
        "# # Summary stats\n",
        "# print(\"\\n=== Summary statistics (FULL) ===\")\n",
        "# display(basic_stats(data).round(4))\n",
        "# print(\"\\n=== Summary statistics (TRAIN) ===\")\n",
        "# display(basic_stats(train).round(4))\n",
        "# print(\"\\n=== Summary statistics (TEST) ===\")\n",
        "# display(basic_stats(test).round(4))\n",
        "\n",
        "# # Train–Test drift checks\n",
        "# print(\"\\n=== Train–Test drift (means & stds) ===\")\n",
        "# drift_rows = []\n",
        "# for col in expected_cols:\n",
        "#     drift_rows.append(drift_summary(train[col].dropna(), test[col].dropna(), col))\n",
        "# drift_df = pd.DataFrame(drift_rows)\n",
        "# display(drift_df.round(3))\n",
        "\n",
        "# # Monthly and diurnal profiles (power)\n",
        "# print(\"\\n=== Monthly mean power (kW) ===\")\n",
        "# monthly_power = data['power'].resample('M').mean()\n",
        "# display(monthly_power.to_frame('mean_power_kW').round(3))\n",
        "\n",
        "# print(\"\\n=== Diurnal profile (average power by hour-of-day) ===\")\n",
        "# hourly_profile = data['power'].groupby(data.index.hour).mean()\n",
        "# display(hourly_profile.to_frame('mean_power_kW').round(3))\n",
        "\n",
        "# # Correlations\n",
        "# print(\"\\n=== Pearson correlation matrix (FULL) ===\")\n",
        "# corr_full = data[expected_cols].corr()\n",
        "# display(corr_full.round(3))\n",
        "\n",
        "# print(\"\\n=== Pearson correlation matrix (TRAIN) ===\")\n",
        "# display(train[expected_cols].corr().round(3))\n",
        "\n",
        "# print(\"\\n=== Pearson correlation matrix (TEST) ===\")\n",
        "# display(test[expected_cols].corr().round(3))\n",
        "\n",
        "# # Simple outlier flags on power\n",
        "# q01, q99 = data['power'].quantile([0.01, 0.99])\n",
        "# outlier_lo = (data['power'] < q01).mean() * 100\n",
        "# outlier_hi = (data['power'] > q99).mean() * 100\n",
        "# print(\"\\n=== Power outlier rates (full) ===\")\n",
        "# print(f\"<1st percentile: {outlier_lo:.2f}% | >99th percentile: {outlier_hi:.2f}%\")\n",
        "\n",
        "# # Missingness overview\n",
        "# print(\"\\n=== Missingness (rows with any NaN) ===\")\n",
        "# print(f\"Full: {data.isna().any(axis=1).mean()*100:.2f}% \"\n",
        "#       f\"| Train: {train.isna().any(axis=1).mean()*100:.2f}% \"\n",
        "#       f\"| Test: {test.isna().any(axis=1).mean()*100:.2f}%\")\n",
        "\n",
        "# # Key facts to help writing\n",
        "# key = {\n",
        "#     \"test_start\": str(test_start.date()),\n",
        "#     \"n_rows_full\": int(data.shape[0]),\n",
        "#     \"n_rows_train\": int(train.shape[0]),\n",
        "#     \"n_rows_test\": int(test.shape[0]),\n",
        "#     \"mean_power_train_kW\": float(train['power'].mean()),\n",
        "#     \"mean_power_test_kW\": float(test['power'].mean()),\n",
        "#     \"irradiation_power_corr_full\": float(corr_full.loc['irradiation','power']),\n",
        "# }\n",
        "# print(\"\\n=== Key facts ===\")\n",
        "# print(key)\n"
      ],
      "metadata": {
        "id": "rSKzjokFLO_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import plotly.graph_objects as go\n",
        "\n",
        "# # Define split point = last 12 months\n",
        "# test_start = pd.to_datetime(end_date) - pd.DateOffset(months=12)\n",
        "\n",
        "# # Split into train and test\n",
        "# train = data[:test_start]\n",
        "# test  = data[test_start:]\n",
        "\n",
        "# # Plot with Plotly\n",
        "# fig = go.Figure()\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=train.index, y=train['power'],\n",
        "#     mode='lines',\n",
        "#     name='Training Data',\n",
        "#     line=dict(color='blue')\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=test.index, y=test['power'],\n",
        "#     mode='lines',\n",
        "#     name='Test Unseen Data (last 12 months)',\n",
        "#     line=dict(color='orange')\n",
        "# ))\n",
        "\n",
        "# fig.update_layout(\n",
        "#     title=\"Training vs Test Data\",\n",
        "#     xaxis_title=\"Date\",\n",
        "#     yaxis_title=\"Power [kW]\",\n",
        "#     template=\"plotly_white\",\n",
        "#     font=dict(size=24),\n",
        "#     legend=dict(\n",
        "#         orientation=\"h\",            # horizontal\n",
        "#         yanchor=\"top\", y=-0.25,     # push below plot\n",
        "#         xanchor=\"center\", x=0.5,    # center it\n",
        "#         font=dict(size=24)\n",
        "#     ),\n",
        "#     xaxis=dict(title_font=dict(size=24), tickfont=dict(size=24)),\n",
        "#     yaxis=dict(title_font=dict(size=24), tickfont=dict(size=24))\n",
        "# )\n",
        "\n",
        "# fig.show()\n"
      ],
      "metadata": {
        "id": "G_qrYYwwI_V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load = data.loc[:, 'power']\n",
        "scaler = MinMaxScaler()\n",
        "load = scaler.fit_transform(load.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "irradiation = data.loc[:, 'irradiation']\n",
        "scaler_w = MinMaxScaler()\n",
        "irradiation = scaler_w.fit_transform(irradiation.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "irradiation = data.loc[:, 'irradiation']\n",
        "\n",
        "load_scaled = pd.DataFrame({\n",
        "    'power_generation': load,\n",
        "    'irradiation': irradiation\n",
        "}, index=data.index)\n",
        "\n",
        "\n",
        "shift_1 = load_scaled.shift(1,axis = 0)\n",
        "shift_1.columns = ['power_generation(t-1)', 'irradiation(t-1)']\n",
        "\n",
        "final_table = pd.concat([load_scaled['power_generation'],shift_1],axis = 1)\n",
        "final_table = final_table.dropna(axis=0)\n",
        "\n",
        "# Extracting components\n",
        "final_table['hour'] = final_table.index.hour\n",
        "final_table['day_of_week'] = final_table.index.weekday\n",
        "final_table['month'] = final_table.index.month\n",
        "\n",
        "# Applying cyclical encoding\n",
        "final_table['hour_sin'] = np.sin(2 * np.pi * final_table['hour'] / 24)\n",
        "final_table['hour_cos'] = np.cos(2 * np.pi * final_table['hour'] / 24)\n",
        "final_table['month_sin'] = np.sin(2 * np.pi * final_table['month'] / 12)\n",
        "final_table['month_cos'] = np.cos(2 * np.pi * final_table['month'] / 12)\n",
        "\n",
        "# Optionally drop the original time components if they are no longer needed\n",
        "final_table.drop(['hour', 'day_of_week', 'month'], axis=1, inplace=True)\n",
        "\n",
        "# Show the modified DataFrame\n",
        "final_table.head(-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ZAvC_046IhJT",
        "outputId": "ec22cc46-6362-45a0-c9ee-67f97ad5dc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     power_generation  power_generation(t-1)  \\\n",
              "datetime                                                       \n",
              "2014-01-01 01:00:00               0.0                    0.0   \n",
              "2014-01-01 02:00:00               0.0                    0.0   \n",
              "2014-01-01 03:00:00               0.0                    0.0   \n",
              "2014-01-01 04:00:00               0.0                    0.0   \n",
              "2014-01-01 05:00:00               0.0                    0.0   \n",
              "...                               ...                    ...   \n",
              "2019-01-31 18:00:00               0.0                    0.0   \n",
              "2019-01-31 19:00:00               0.0                    0.0   \n",
              "2019-01-31 20:00:00               0.0                    0.0   \n",
              "2019-01-31 21:00:00               0.0                    0.0   \n",
              "2019-01-31 22:00:00               0.0                    0.0   \n",
              "\n",
              "                     irradiation(t-1)  hour_sin      hour_cos  month_sin  \\\n",
              "datetime                                                                   \n",
              "2014-01-01 01:00:00          0.496861  0.258819  9.659258e-01        0.5   \n",
              "2014-01-01 02:00:00          0.379389  0.500000  8.660254e-01        0.5   \n",
              "2014-01-01 03:00:00          0.257452  0.707107  7.071068e-01        0.5   \n",
              "2014-01-01 04:00:00          0.209292  0.866025  5.000000e-01        0.5   \n",
              "2014-01-01 05:00:00          0.019541  0.965926  2.588190e-01        0.5   \n",
              "...                               ...       ...           ...        ...   \n",
              "2019-01-31 18:00:00          1.006410 -1.000000 -1.836970e-16        0.5   \n",
              "2019-01-31 19:00:00          1.037107 -0.965926  2.588190e-01        0.5   \n",
              "2019-01-31 20:00:00          1.346272 -0.866025  5.000000e-01        0.5   \n",
              "2019-01-31 21:00:00          1.288054 -0.707107  7.071068e-01        0.5   \n",
              "2019-01-31 22:00:00          1.344754 -0.500000  8.660254e-01        0.5   \n",
              "\n",
              "                     month_cos  \n",
              "datetime                        \n",
              "2014-01-01 01:00:00   0.866025  \n",
              "2014-01-01 02:00:00   0.866025  \n",
              "2014-01-01 03:00:00   0.866025  \n",
              "2014-01-01 04:00:00   0.866025  \n",
              "2014-01-01 05:00:00   0.866025  \n",
              "...                        ...  \n",
              "2019-01-31 18:00:00   0.866025  \n",
              "2019-01-31 19:00:00   0.866025  \n",
              "2019-01-31 20:00:00   0.866025  \n",
              "2019-01-31 21:00:00   0.866025  \n",
              "2019-01-31 22:00:00   0.866025  \n",
              "\n",
              "[44566 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05b480a7-4d20-4c5b-94ff-d7097c9dbf76\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>power_generation</th>\n",
              "      <th>power_generation(t-1)</th>\n",
              "      <th>irradiation(t-1)</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-01-01 01:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.496861</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>9.659258e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-01 02:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.379389</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.660254e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-01 03:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257452</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>7.071068e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-01 04:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209292</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-01 05:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019541</td>\n",
              "      <td>0.965926</td>\n",
              "      <td>2.588190e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-31 18:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.006410</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-31 19:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.037107</td>\n",
              "      <td>-0.965926</td>\n",
              "      <td>2.588190e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-31 20:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.346272</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-31 21:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.288054</td>\n",
              "      <td>-0.707107</td>\n",
              "      <td>7.071068e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-31 22:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.344754</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>8.660254e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44566 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05b480a7-4d20-4c5b-94ff-d7097c9dbf76')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05b480a7-4d20-4c5b-94ff-d7097c9dbf76 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05b480a7-4d20-4c5b-94ff-d7097c9dbf76');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4c155ab4-b809-4f85-a28f-ac174d72f6d4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c155ab4-b809-4f85-a28f-ac174d72f6d4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4c155ab4-b809-4f85-a28f-ac174d72f6d4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_table",
              "summary": "{\n  \"name\": \"final_table\",\n  \"rows\": 44567,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-01-01 01:00:00\",\n        \"max\": \"2019-01-31 23:00:00\",\n        \"num_unique_values\": 44567,\n        \"samples\": [\n          \"2015-06-23 06:00:00\",\n          \"2016-06-29 15:00:00\",\n          \"2014-02-11 17:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"power_generation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2338908455751774,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 22908,\n        \"samples\": [\n          0.03749062012862832,\n          0.24578123217088124,\n          5.43471340209873e-07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"power_generation(t-1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2338908455751774,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 22908,\n        \"samples\": [\n          0.03749062012862832,\n          0.24578123217088124,\n          5.43471340209873e-07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"irradiation(t-1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 241.7913657900142,\n        \"min\": 0.0,\n        \"max\": 1127.75315713483,\n        \"num_unique_values\": 39713,\n        \"samples\": [\n          383.254239492318,\n          0.993055499997262,\n          43.2568357340926\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour_sin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071226475162183,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.25881904510252074,\n          -0.8660254037844384,\n          0.258819045102521\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour_cos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.707106780830507,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.9659258262890683,\n          -0.8660254037844388,\n          -0.7071067811865475\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month_sin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7028129572174697,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -0.4999999999999997,\n          0.49999999999999994,\n          -0.5000000000000004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month_cos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.711274128755156,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -1.0,\n          0.8660254037844387,\n          0.8660254037844384\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_start_date = final_table.index[-1] - pd.DateOffset(months=12)\n",
        "train_set = final_table[final_table.index < test_set_start_date]\n",
        "test_set = final_table[final_table.index >= test_set_start_date]"
      ],
      "metadata": {
        "id": "SAfT3YIKImVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # === Config ===\n",
        "# TARGET_COL   = 'power_generation'\n",
        "# FEATURE_COLS = None          # None -> use all columns; or set a list manually\n",
        "# SEQ_LEN      = 96            # lookback\n",
        "# PRED_LEN     = 1            # horizon\n",
        "# BATCH_SIZE   = 256\n",
        "# EPOCHS       = 10\n",
        "# LR           = 3e-4\n",
        "# WEIGHT_DECAY = 1e-4\n",
        "# DROPOUT      = 0.2\n",
        "# D_MODEL      = 128\n",
        "# D_FF         = 256\n",
        "# E_LAYERS     = 3\n",
        "# N_HEADS      = 8\n",
        "# PATCH_LEN    = 16\n",
        "# STRIDE       = 8\n",
        "# INDIVIDUAL   = True          # separate head per variable; we will index the target channel for loss\n",
        "# PATIENCE     = 5             # early stopping\n",
        "# SEED         = 2025\n",
        "\n",
        "# import numpy as np, pandas as pd, torch, torch.nn as nn, torch.optim as optim\n",
        "# from types import SimpleNamespace\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# torch.manual_seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "# # --- 0) Train/test split already done by you. We assume `final_table`, `train_set`, `test_set` exist. ---\n",
        "# assert TARGET_COL in final_table.columns, \"TARGET_COL not in final_table!\"\n",
        "\n",
        "# # --- 1) Columns / scalers ---\n",
        "# if FEATURE_COLS is None:\n",
        "#     FEATURE_COLS = list(final_table.columns)   # all columns, including target\n",
        "# enc_in = len(FEATURE_COLS)\n",
        "# tgt_idx = FEATURE_COLS.index(TARGET_COL)\n",
        "\n",
        "# x_scaler = StandardScaler()\n",
        "# y_scaler = StandardScaler()\n",
        "\n",
        "# # fit on TRAIN only\n",
        "# X_train_df = train_set[FEATURE_COLS].copy()\n",
        "# y_train_df = train_set[[TARGET_COL]].copy()\n",
        "\n",
        "# X_train = x_scaler.fit_transform(X_train_df.values)\n",
        "# y_train = y_scaler.fit_transform(y_train_df.values).ravel()  # (N,)\n",
        "\n",
        "# # transform test\n",
        "# X_test = x_scaler.transform(test_set[FEATURE_COLS].values)\n",
        "# y_test = y_scaler.transform(test_set[[TARGET_COL]].values).ravel()\n",
        "\n",
        "# # For windowing we need aligned arrays over time for each split\n",
        "# def build_xy(X, y, seq_len, pred_len):\n",
        "#     \"\"\"\n",
        "#     X: (T, N_feat), y: (T,), both already scaled\n",
        "#     Returns:\n",
        "#       X_seq: (num, seq_len, N_feat)\n",
        "#       Y_seq: (num, pred_len) target-only\n",
        "#     \"\"\"\n",
        "#     T = len(X)\n",
        "#     num = T - seq_len - pred_len + 1\n",
        "#     Xs = np.zeros((num, seq_len, X.shape[1]), dtype=np.float32)\n",
        "#     Ys = np.zeros((num, pred_len), dtype=np.float32)\n",
        "#     for i in range(num):\n",
        "#         Xs[i] = X[i:i+seq_len]\n",
        "#         Ys[i] = y[i+seq_len : i+seq_len+pred_len]\n",
        "#     return Xs, Ys\n",
        "\n",
        "# Xtr, Ytr = build_xy(X_train, y_train, SEQ_LEN, PRED_LEN)\n",
        "# Xte, Yte = build_xy(X_test,  y_test,  SEQ_LEN, PRED_LEN)\n",
        "\n",
        "# class TSDS(Dataset):\n",
        "#     def __init__(self, X, Y):\n",
        "#         self.X = torch.from_numpy(X)     # (B, L, N)\n",
        "#         self.Y = torch.from_numpy(Y)     # (B, pred_len)\n",
        "#     def __len__(self): return self.X.shape[0]\n",
        "#     def __getitem__(self, i): return self.X[i], self.Y[i]\n",
        "\n",
        "# dtr = DataLoader(TSDS(Xtr, Ytr), batch_size=BATCH_SIZE,\n",
        "#                  sampler=RandomSampler(TSDS(Xtr, Ytr)), drop_last=True)\n",
        "# dte = DataLoader(TSDS(Xte, Yte), batch_size=BATCH_SIZE,\n",
        "#                  sampler=SequentialSampler(TSDS(Xte, Yte)))\n",
        "\n",
        "# # --- 2) Build PatchTST model (using your imported Model class) ---\n",
        "# # The supervised repo expects a \"configs\" namespace with these fields:\n",
        "# cfg = SimpleNamespace(\n",
        "#     task_name='forecasting',\n",
        "#     output_attention=False,\n",
        "#     enc_in=enc_in,\n",
        "\n",
        "#     # >>> add the fields your repo expects\n",
        "#     fc_dropout=DROPOUT,      # e.g., 0.2\n",
        "#     head_dropout=DROPOUT,    # 0.0–0.2 is typical\n",
        "#     head_type='flatten',     # forecasting head\n",
        "#     c_out=enc_in,            # predict all channels; we'll pick target later\n",
        "#     revin=True,             # set True if you want RevIN\n",
        "\n",
        "#     seq_len=SEQ_LEN,\n",
        "#     pred_len=PRED_LEN,\n",
        "#     patch_len=PATCH_LEN,\n",
        "#     stride=STRIDE,\n",
        "#     d_model=D_MODEL,\n",
        "#     n_heads=N_HEADS,\n",
        "#     e_layers=E_LAYERS,\n",
        "#     d_ff=D_FF,\n",
        "#     dropout=DROPOUT,\n",
        "#     activation='gelu',\n",
        "#     affine=True,\n",
        "#     individual=INDIVIDUAL,\n",
        "#     pre_norm=False,\n",
        "#     padding_patch='end',\n",
        "#     subtract_last=False,   # if your fork supports last-value normalization\n",
        "#     decomposition=False,       # if True, also set kernel_size\n",
        "#     kernel_size=25,        # only used when decompose=True\n",
        "# )\n",
        "\n",
        "\n",
        "# model = PatchTST(cfg).to(device)\n",
        "\n",
        "# # quick shape check to avoid \"no core\" style mistakes\n",
        "# with torch.no_grad():\n",
        "#     _x = torch.randn(2, SEQ_LEN, enc_in, device=device)\n",
        "#     _y = model(_x)   # expected: (2, PRED_LEN, enc_in) if individual=False; or (2, PRED_LEN, enc_in) for most forks\n",
        "#     print(\"Sanity forward:\", tuple(_y.shape))\n",
        "\n",
        "# # --- 3) Train setup ---\n",
        "# # --- 3) Train setup (no val/scheduler/early stopping) ---\n",
        "# optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "# criterion  = nn.MSELoss()\n",
        "\n",
        "# for epoch in range(1, EPOCHS+1):\n",
        "#     model.train()\n",
        "#     tr_loss = 0.0\n",
        "#     for xb, yb in dtr:\n",
        "#         xb = xb.to(device)\n",
        "#         yb = yb.to(device)                 # (B, pred_len)\n",
        "#         yp = model(xb)[:, :, tgt_idx]      # (B, pred_len)\n",
        "#         loss = criterion(yp, yb)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#         optimizer.step()\n",
        "\n",
        "#         tr_loss += loss.item() * xb.size(0)\n",
        "#     tr_loss /= len(dtr.dataset)\n",
        "#     print(f\"Epoch {epoch:02d} | train MSE {tr_loss:.5f}\")\n",
        "\n",
        "\n",
        "# # --- 4) Evaluation (MAE/RMSE) in original units on the test set ---\n",
        "# def inverse_to_raw(y_std_flat):\n",
        "#     \"\"\"\n",
        "#     y_std_flat: flattened array in StandardScaler space (which was applied on top of MinMax space).\n",
        "#     Returns: flattened array in ORIGINAL units (same units as data['power']).\n",
        "#     \"\"\"\n",
        "#     # 1) undo StandardScaler (back to MinMax space)\n",
        "#     y_mm = y_scaler.inverse_transform(y_std_flat.reshape(-1, 1)).reshape(-1)\n",
        "#     # 2) undo MinMax (back to original units)\n",
        "#     y_raw = scaler.inverse_transform(y_mm.reshape(-1, 1)).reshape(-1)\n",
        "#     return y_raw\n",
        "\n",
        "# model.eval()\n",
        "# preds_scaled = []\n",
        "# truth_scaled = []\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for xb, yb in dte:\n",
        "#         xb = xb.to(device)\n",
        "#         yp = model(xb)[:, :, tgt_idx]  # (B, pred_len)\n",
        "#         preds_scaled.append(yp.detach().cpu().numpy())\n",
        "#         truth_scaled.append(yb.numpy())\n",
        "\n",
        "# preds_scaled = np.concatenate(preds_scaled, axis=0)   # (num, pred_len)\n",
        "# truth_scaled = np.concatenate(truth_scaled, axis=0)\n",
        "\n",
        "# # back to ORIGINAL units\n",
        "# preds_real = inverse_to_raw(preds_scaled.ravel()).reshape(preds_scaled.shape)\n",
        "# truth_real = inverse_to_raw(truth_scaled.ravel()).reshape(truth_scaled.shape)\n",
        "\n",
        "# mae = np.mean(np.abs(preds_real - truth_real))\n",
        "# rmse = np.sqrt(np.mean((preds_real - truth_real)**2))\n",
        "# mbe = np.mean(preds_real - truth_real)\n",
        "# print(f\"Test MAE (real units):  {mae:.4f}\")\n",
        "\n",
        "# print(f\"Test RMSE (real units): {rmse:.4f}\")\n",
        "# print(f\"Test MBE (real units): {mbe:.4f}\")\n"
      ],
      "metadata": {
        "id": "e4CEcg5lKwo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_crps(actual, lower, upper):\n",
        "    \"\"\"\n",
        "    Computes CRPS using a quantile-based approximation.\n",
        "    \"\"\"\n",
        "    if actual < lower:\n",
        "        return (upper - lower) + ((lower - actual) ** 2) / (upper - lower)\n",
        "    elif actual > upper:\n",
        "        return (upper - lower) + ((actual - upper) ** 2) / (upper - lower)\n",
        "    else:\n",
        "        return (upper - lower) / 2\n",
        "\n",
        "def compute_winkler_score(y_true, y_lower, y_upper, alpha=0.1):\n",
        "    \"\"\"\n",
        "    Computes the Winkler Score.\n",
        "\n",
        "    Args:\n",
        "        y_true (float): The actual observed value.\n",
        "        y_lower (float): The predicted lower quantile.\n",
        "        y_upper (float): The predicted upper quantile.\n",
        "        alpha (float): The significance level (default 0.1 for a 90% prediction interval).\n",
        "\n",
        "    Returns:\n",
        "        float: Winkler score for the given forecast.\n",
        "    \"\"\"\n",
        "    interval_width = y_upper - y_lower\n",
        "\n",
        "    if y_true < y_lower:\n",
        "        return interval_width + (2 / alpha) * (y_lower - y_true)\n",
        "    elif y_true > y_upper:\n",
        "        return interval_width + (2 / alpha) * (y_true - y_upper)\n",
        "    else:\n",
        "        return interval_width"
      ],
      "metadata": {
        "id": "a2BZMdOC9Ig0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# PatchTST (no extra scalers; invert with your original MinMax \"scaler\")\n",
        "# =========================\n",
        "import os, numpy as np, pandas as pd, torch, torch.nn as nn, torch.optim as optim\n",
        "from types import SimpleNamespace\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# ---- Assumptions from your pipeline ----\n",
        "# - final_table is already built and scaled (power_generation in MinMax space using `scaler`)\n",
        "# - train_set, test_set are already split from final_table\n",
        "# - PatchTST class is imported as PatchTST\n",
        "# - `scaler` is the SAME MinMaxScaler used on the raw power series\n",
        "\n",
        "# ---- Config ----\n",
        "TARGET_COL   = 'power_generation'   # scaled in [0,1] by your original MinMax \"scaler\"\n",
        "FEATURE_COLS = None                 # None -> all columns in final_table\n",
        "SEQ_LEN      = 48\n",
        "PRED_LEN     = 1\n",
        "BATCH_SIZE   = 48\n",
        "EPOCHS       = 10\n",
        "LR           = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "DROPOUT      = 0.1\n",
        "D_MODEL      = 128\n",
        "D_FF         = 256\n",
        "E_LAYERS     = 3\n",
        "N_HEADS      = 4\n",
        "PATCH_LEN    = 16\n",
        "STRIDE       = 8\n",
        "INDIVIDUAL   = True\n",
        "SEED         = 2025\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "assert TARGET_COL in final_table.columns, \"TARGET_COL missing in final_table\"\n",
        "if FEATURE_COLS is None:\n",
        "    FEATURE_COLS = list(final_table.columns)\n",
        "\n",
        "enc_in  = len(FEATURE_COLS)\n",
        "tgt_idx = FEATURE_COLS.index(TARGET_COL)\n",
        "\n",
        "# ---- Use the data AS-IS (already scaled); no new scalers here ----\n",
        "X_train = train_set[FEATURE_COLS].values.astype(np.float32)\n",
        "y_train = train_set[[TARGET_COL]].values.astype(np.float32).ravel()\n",
        "X_test  = test_set[FEATURE_COLS].values.astype(np.float32)\n",
        "y_test  = test_set[[TARGET_COL]].values.astype(np.float32).ravel()\n",
        "\n",
        "def build_xy(X, y_scaled, seq_len, pred_len):\n",
        "    T   = len(X)\n",
        "    num = T - seq_len - pred_len + 1\n",
        "    Xs  = np.zeros((num, seq_len, X.shape[1]), dtype=np.float32)\n",
        "    Ys  = np.zeros((num, pred_len), dtype=np.float32)  # still in scaled space\n",
        "    for i in range(num):\n",
        "        Xs[i] = X[i:i+seq_len]\n",
        "        Ys[i] = y_scaled[i+seq_len : i+seq_len+pred_len]\n",
        "    return Xs, Ys\n",
        "\n",
        "Xtr, Ytr = build_xy(X_train, y_train, SEQ_LEN, PRED_LEN)\n",
        "Xte, Yte = build_xy(X_test,  y_test,  SEQ_LEN, PRED_LEN)\n",
        "\n",
        "class TSDS(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = torch.from_numpy(X)   # (B, L, N)\n",
        "        self.Y = torch.from_numpy(Y)   # (B, pred_len) in scaled space\n",
        "    def __len__(self):  return self.X.shape[0]\n",
        "    def __getitem__(self, i): return self.X[i], self.Y[i]\n",
        "\n",
        "dtr = DataLoader(TSDS(Xtr, Ytr), batch_size=BATCH_SIZE,\n",
        "                 sampler=RandomSampler(TSDS(Xtr, Ytr)), drop_last=True)\n",
        "dte = DataLoader(TSDS(Xte, Yte), batch_size=BATCH_SIZE,\n",
        "                 sampler=SequentialSampler(TSDS(Xte, Yte)))\n",
        "\n",
        "# ---- Build PatchTST (no RevIN, to avoid hidden normalization) ----\n",
        "cfg = SimpleNamespace(\n",
        "    task_name='forecasting', output_attention=False,\n",
        "    enc_in=enc_in, c_out=enc_in, individual=INDIVIDUAL,\n",
        "    seq_len=SEQ_LEN, pred_len=PRED_LEN,\n",
        "    patch_len=PATCH_LEN, stride=STRIDE,\n",
        "    d_model=D_MODEL, n_heads=N_HEADS, e_layers=E_LAYERS, d_ff=D_FF,\n",
        "    dropout=DROPOUT, activation='gelu',\n",
        "    revin=False, affine = True, fc_dropout=DROPOUT, head_dropout=DROPOUT, head_type='flatten',\n",
        "    pre_norm=False, padding_patch='end', subtract_last=False,\n",
        "    decomposition=False, kernel_size=25\n",
        ")\n",
        "model = PatchTST(cfg).to(device)\n",
        "\n",
        "# quick shape check\n",
        "with torch.no_grad():\n",
        "    _y = model(torch.randn(2, SEQ_LEN, enc_in, device=device))\n",
        "    print(\"Forward shape:\", tuple(_y.shape))  # usually (2, pred_len, enc_in)\n",
        "\n",
        "# ---- Train ----\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "criterion  = nn.MSELoss()\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train(); tr_loss = 0.0\n",
        "    for xb, yb in dtr:\n",
        "        xb = xb.to(device); yb = yb.to(device)             # yb in scaled space\n",
        "        yp = model(xb)[:, :, tgt_idx]                      # (B, pred_len), scaled\n",
        "        loss = criterion(yp, yb)\n",
        "        optimizer.zero_grad(); loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        tr_loss += loss.item() * xb.size(0)\n",
        "    tr_loss /= len(dtr.dataset)\n",
        "    print(f\"Epoch {ep:02d} | train MSE {tr_loss:.5f}\")\n",
        "\n",
        "# ---- Predict (still scaled), then invert ONCE using your original MinMax \"scaler\" ----\n",
        "model.eval()\n",
        "preds_scaled = []\n",
        "with torch.no_grad():\n",
        "    for xb, _ in dte:\n",
        "        xb = xb.to(device)\n",
        "        yp = model(xb)[:, :, tgt_idx]                      # scaled\n",
        "        preds_scaled.append(yp.detach().cpu().numpy())\n",
        "preds_scaled = np.concatenate(preds_scaled, axis=0)        # (num, pred_len)\n",
        "\n",
        "# Invert to kW using *your* original MinMax scaler\n",
        "preds_raw  = scaler.inverse_transform(preds_scaled.reshape(-1, 1)).reshape(preds_scaled.shape)\n",
        "truth_raw  = scaler.inverse_transform(Yte.reshape(-1, 1)).reshape(Yte.shape)\n",
        "\n",
        "# Optional: snap tiny residuals to zero (to avoid 3e-08 at night)\n",
        "preds_raw[np.isclose(preds_raw, 0, atol=1e-6)] = 0.0\n",
        "truth_raw[np.isclose(truth_raw, 0, atol=1e-12)] = 0.0\n",
        "\n",
        "# ---- Metrics in kW ----\n",
        "mae  = float(np.mean(np.abs(preds_raw - truth_raw)))\n",
        "rmse = float(np.sqrt(np.mean((preds_raw - truth_raw)**2)))\n",
        "mbe  = float(np.mean(preds_raw - truth_raw))\n",
        "print(f\"Test MAE:  {mae:.4f} kW\")\n",
        "print(f\"Test RMSE: {rmse:.4f} kW\")\n",
        "print(f\"Test MBE:  {mbe:.4f} kW\")\n",
        "\n",
        "# Flatten to 1D arrays\n",
        "yhat_act = preds_raw\n",
        "y_check_act = truth_raw\n",
        "\n",
        "# # === Correction Rules ===\n",
        "# # Rule 1: clip negative forecasts\n",
        "# yhat_act[yhat_act < 0] = 0.0\n",
        "\n",
        "# # Rule 2: if actual[t] == 0 → forecast[t+1] = 0\n",
        "# zero_idx = np.where(y_check_act == 0)[0] + 1\n",
        "# zero_idx = zero_idx[zero_idx < len(yhat_act)]\n",
        "# yhat_act[zero_idx] = 0.0\n",
        "\n",
        "\n",
        "# === ACI evaluation after point prediction with model_stacked_mamba ===\n",
        "y_lowers_mamba_ACI = np.empty(len(yhat_act))\n",
        "y_uppers_mamba_ACI = np.empty(len(yhat_act))\n",
        "err_i_mamba_ACI = np.empty(len(yhat_act))\n",
        "alpha_t_i_mamba_ACI = np.empty(len(yhat_act))\n",
        "window_i_mamba_ACI = np.empty(len(yhat_act))\n",
        "res_cal_acp_mamba_ACI = np.empty(len(yhat_act))\n",
        "alpha_t_mamba_ACI = 0.1\n",
        "gamma_mamba_ACI = 0.01\n",
        "\n",
        "# Initialize Metrics\n",
        "crps_mamba_ACI = np.zeros(len(yhat_act))\n",
        "winkler_mamba_ACI = np.zeros(len(yhat_act))\n",
        "\n",
        "for i in range(1, len(yhat_act)):\n",
        "    res_cal_acp_mamba_ACI = np.abs(yhat_act - y_check_act)\n",
        "\n",
        "    if alpha_t_mamba_ACI >= 1:\n",
        "        y_lowers_mamba_ACI[i], y_uppers_mamba_ACI[i] = 0, 0\n",
        "        err_mamba_ACI = 1\n",
        "    elif alpha_t_mamba_ACI <= 0:\n",
        "        y_lowers_mamba_ACI[i], y_uppers_mamba_ACI[i] = 0, 0\n",
        "        err_mamba_ACI = 0\n",
        "        alpha_t_mamba_ACI = 0.1\n",
        "    else:\n",
        "        window_mamba_ACI = np.quantile(res_cal_acp_mamba_ACI, (1 - alpha_t_mamba_ACI))\n",
        "        y_lowers_mamba_ACI[i] = yhat_act[i] - window_mamba_ACI\n",
        "        y_uppers_mamba_ACI[i] = yhat_act[i] + window_mamba_ACI\n",
        "        err_mamba_ACI = 1 - float((y_lowers_mamba_ACI[i] <= y_check_act[i]) and (y_check_act[i] <= y_uppers_mamba_ACI[i]))\n",
        "\n",
        "    # Update alpha\n",
        "    alpha_t_mamba_ACI += gamma_mamba_ACI * (alpha_t_mamba_ACI - err_mamba_ACI)\n",
        "    if alpha_t_mamba_ACI < 0.1 or alpha_t_mamba_ACI > 0.3:\n",
        "        alpha_t_mamba_ACI = 0.1\n",
        "\n",
        "    # Store metrics\n",
        "    alpha_t_i_mamba_ACI[i] = alpha_t_mamba_ACI\n",
        "    err_i_mamba_ACI[i] = err_mamba_ACI\n",
        "    window_i_mamba_ACI[i] = window_mamba_ACI\n",
        "\n",
        "    crps_mamba_ACI[i] = compute_crps(y_check_act[i], y_lowers_mamba_ACI[i], y_uppers_mamba_ACI[i])\n",
        "    winkler_mamba_ACI[i] = compute_winkler_score(y_check_act[i], y_lowers_mamba_ACI[i], y_uppers_mamba_ACI[i], alpha=0.1)\n",
        "\n",
        "# Post-processing: Bound clipping and reshaping\n",
        "y_lowers_mamba_ACI[y_lowers_mamba_ACI < 0] = 0\n",
        "y_uppers_mamba_ACI[y_uppers_mamba_ACI > max(y_check_act)] = max(y_check_act)\n",
        "y_lowers_mamba_ACI = y_lowers_mamba_ACI.reshape(-1, 1)\n",
        "y_uppers_mamba_ACI = y_uppers_mamba_ACI.reshape(-1, 1)\n",
        "\n",
        "# Interval metrics\n",
        "interval_widths_mamba_ACI = y_uppers_mamba_ACI - y_lowers_mamba_ACI\n",
        "mean_interval_width_mamba_ACI = np.mean(interval_widths_mamba_ACI)\n",
        "covered_mamba_ACI = (y_check_act >= y_lowers_mamba_ACI) & (y_check_act <= y_uppers_mamba_ACI)\n",
        "coverage_percentage_mamba_ACI = np.mean(covered_mamba_ACI) * 100\n",
        "mean_crps_mamba_ACI = np.mean(crps_mamba_ACI)\n",
        "mean_winkler_mamba_ACI = np.mean(winkler_mamba_ACI)\n",
        "\n",
        "# Final results\n",
        "print(f\"Mean Interval Width: {mean_interval_width_mamba_ACI}\")\n",
        "print(f\"Coverage Percentage: {coverage_percentage_mamba_ACI}%\")\n",
        "print(f\"Mean CRPS: {mean_crps_mamba_ACI}\")\n",
        "print(f\"Mean Winkler Score: {mean_winkler_mamba_ACI}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hWfMb4z56jj",
        "outputId": "b3a6ce97-dd56-4b52-bd3a-34bdbd1a3ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward shape: (2, 1, 7)\n",
            "Epoch 01 | train MSE 0.03074\n",
            "Epoch 02 | train MSE 0.01635\n",
            "Epoch 03 | train MSE 0.01564\n",
            "Epoch 04 | train MSE 0.01549\n",
            "Epoch 05 | train MSE 0.01432\n",
            "Epoch 06 | train MSE 0.01334\n",
            "Epoch 07 | train MSE 0.01391\n",
            "Epoch 08 | train MSE 0.01490\n",
            "Epoch 09 | train MSE 0.01355\n",
            "Epoch 10 | train MSE 0.01277\n",
            "Test MAE:  0.1912 kW\n",
            "Test RMSE: 0.3501 kW\n",
            "Test MBE:  -0.0471 kW\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-557394183.py:175: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n",
            "/tmp/ipython-input-557394183.py:176: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n",
            "/tmp/ipython-input-557394183.py:177: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n",
            "/tmp/ipython-input-557394183.py:189: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n",
            "/tmp/ipython-input-557394183.py:190: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Interval Width: 0.6237166094736186\n",
            "Coverage Percentage: 86.17009066911511%\n",
            "Mean CRPS: 0.5387949939319495\n",
            "Mean Winkler Score: 1.8610488975033919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import itertools, random, time\n",
        "# import numpy as np, pandas as pd, torch\n",
        "# import torch.nn as nn, torch.optim as optim\n",
        "# from types import SimpleNamespace\n",
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# # === ACI function ===\n",
        "# def run_ACI(yhat_act, y_check_act, alpha0=0.1, gamma=0.01):\n",
        "#     n = len(yhat_act)\n",
        "#     y_lowers = np.empty(n)\n",
        "#     y_uppers = np.empty(n)\n",
        "#     crps = np.zeros(n)\n",
        "#     winkler = np.zeros(n)\n",
        "#     alpha_t = alpha0\n",
        "\n",
        "#     for i in range(1, n):\n",
        "#         res_cal = np.abs(yhat_act - y_check_act)\n",
        "#         if alpha_t >= 1:\n",
        "#             y_lowers[i], y_uppers[i] = 0, 0\n",
        "#             err = 1\n",
        "#         elif alpha_t <= 0:\n",
        "#             y_lowers[i], y_uppers[i] = 0, 0\n",
        "#             err = 0\n",
        "#             alpha_t = alpha0\n",
        "#         else:\n",
        "#             window = np.quantile(res_cal, (1 - alpha_t))\n",
        "#             y_lowers[i] = yhat_act[i] - window\n",
        "#             y_uppers[i] = yhat_act[i] + window\n",
        "#             err = 1 - float((y_lowers[i] <= y_check_act[i]) and (y_check_act[i] <= y_uppers[i]))\n",
        "#         # update alpha\n",
        "#         alpha_t += gamma * (alpha_t - err)\n",
        "#         if alpha_t < 0.1 or alpha_t > 0.3:\n",
        "#             alpha_t = alpha0\n",
        "#         # metrics\n",
        "#         crps[i] = compute_crps(y_check_act[i], y_lowers[i], y_uppers[i])\n",
        "#         winkler[i] = compute_winkler_score(y_check_act[i], y_lowers[i], y_uppers[i], alpha=alpha0)\n",
        "\n",
        "#     # clip intervals\n",
        "#     y_lowers[y_lowers < 0] = 0\n",
        "#     y_uppers[y_uppers > max(y_check_act)] = max(y_check_act)\n",
        "\n",
        "#     # summary metrics\n",
        "#     interval_widths = y_uppers - y_lowers\n",
        "#     mean_interval_width = np.mean(interval_widths)\n",
        "#     covered = (y_check_act >= y_lowers) & (y_check_act <= y_uppers)\n",
        "#     coverage = np.mean(covered) * 100\n",
        "#     mean_crps = np.mean(crps)\n",
        "#     mean_winkler = np.mean(winkler)\n",
        "\n",
        "#     return coverage, mean_interval_width, mean_crps, mean_winkler\n",
        "\n",
        "\n",
        "# # --- Define search space ---\n",
        "# param_grid = {\n",
        "#     \"SEQ_LEN\":   [24],\n",
        "#     \"BATCH_SIZE\": [48],\n",
        "#     \"LR\":        [0.001],\n",
        "#     \"D_MODEL\":   [64],\n",
        "#     \"N_HEADS\":   [4],\n",
        "#     \"PATCH_LEN\": [8],\n",
        "#     \"STRIDE\":    [8],\n",
        "#     \"E_LAYERS\":  [3],\n",
        "# }\n",
        "\n",
        "# # Generate all combinations (or sample a subset)\n",
        "# all_combos = list(itertools.product(*param_grid.values()))\n",
        "# print(f\"Total combinations: {len(all_combos)}\")\n",
        "# random.shuffle(all_combos)\n",
        "# all_combos = all_combos[:20]   # <-- sample 20 for speed, adjust as needed\n",
        "\n",
        "\n",
        "# # --- Utility: train + eval PatchTST once ---\n",
        "# def train_eval_patchtst(params, train_set, test_set, scaler, TARGET_COL=\"power_generation\"):\n",
        "#     SEQ_LEN, BATCH_SIZE, LR, D_MODEL, N_HEADS, PATCH_LEN, STRIDE, E_LAYERS = params\n",
        "\n",
        "#     # === Prepare data ===\n",
        "#     FEATURE_COLS = list(train_set.columns)\n",
        "#     tgt_idx = FEATURE_COLS.index(TARGET_COL)\n",
        "\n",
        "#     def build_xy(X, y, seq_len, pred_len):\n",
        "#         T = len(X); num = T - seq_len - pred_len + 1\n",
        "#         Xs = np.zeros((num, seq_len, X.shape[1]), dtype=np.float32)\n",
        "#         Ys = np.zeros((num, pred_len), dtype=np.float32)\n",
        "#         for i in range(num):\n",
        "#             Xs[i] = X[i:i+seq_len]\n",
        "#             Ys[i] = y[i+seq_len : i+seq_len+pred_len]\n",
        "#         return Xs, Ys\n",
        "\n",
        "#     Xtr, Ytr = build_xy(\n",
        "#         train_set[FEATURE_COLS].values.astype(np.float32),\n",
        "#         train_set[[TARGET_COL]].values.astype(np.float32).ravel(),\n",
        "#         SEQ_LEN, 1\n",
        "#     )\n",
        "#     Xte, Yte = build_xy(\n",
        "#         test_set[FEATURE_COLS].values.astype(np.float32),\n",
        "#         test_set[[TARGET_COL]].values.astype(np.float32).ravel(),\n",
        "#         SEQ_LEN, 1\n",
        "#     )\n",
        "\n",
        "#     # Torch datasets\n",
        "#     class TSDS(torch.utils.data.Dataset):\n",
        "#         def __init__(self, X, Y):\n",
        "#             self.X = torch.from_numpy(X); self.Y = torch.from_numpy(Y)\n",
        "#         def __len__(self): return self.X.shape[0]\n",
        "#         def __getitem__(self,i): return self.X[i], self.Y[i]\n",
        "\n",
        "#     dtr = DataLoader(TSDS(Xtr, Ytr), batch_size=BATCH_SIZE,\n",
        "#                      sampler=RandomSampler(TSDS(Xtr, Ytr)), drop_last=True)\n",
        "#     dte = DataLoader(TSDS(Xte, Yte), batch_size=BATCH_SIZE,\n",
        "#                      sampler=SequentialSampler(TSDS(Xte, Yte)))\n",
        "\n",
        "#     # === Build model ===\n",
        "#     cfg = SimpleNamespace(\n",
        "#         task_name='forecasting', output_attention=False,\n",
        "#         enc_in=len(FEATURE_COLS), c_out=len(FEATURE_COLS), individual=True,\n",
        "#         seq_len=SEQ_LEN, pred_len=1,\n",
        "#         patch_len=PATCH_LEN, stride=STRIDE,\n",
        "#         d_model=D_MODEL, n_heads=N_HEADS, e_layers=E_LAYERS, d_ff=256,\n",
        "#         dropout=0.1, activation='gelu',\n",
        "#         revin=False, fc_dropout=0.1, head_dropout=0.1, head_type='flatten',\n",
        "#         pre_norm=False, padding_patch='end', subtract_last=False,\n",
        "#         decomposition=False, kernel_size=25, affine=True\n",
        "#     )\n",
        "#     model = PatchTST(cfg).to(device)\n",
        "\n",
        "#     optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "#     criterion = nn.MSELoss()\n",
        "\n",
        "#     # === Train quick ===\n",
        "#     for ep in range(5):   # short run for search\n",
        "#         model.train(); tr_loss = 0\n",
        "#         for xb, yb in dtr:\n",
        "#             xb, yb = xb.to(device), yb.to(device)\n",
        "#             yp = model(xb)[:, :, tgt_idx]\n",
        "#             loss = criterion(yp, yb)\n",
        "#             optimizer.zero_grad(); loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#             optimizer.step()\n",
        "#             tr_loss += loss.item() * xb.size(0)\n",
        "#         tr_loss /= len(dtr.dataset)\n",
        "\n",
        "#     # === Evaluate point metrics ===\n",
        "#     model.eval(); preds_scaled = []\n",
        "#     with torch.no_grad():\n",
        "#         for xb, yb in dte:\n",
        "#             xb = xb.to(device)\n",
        "#             yp = model(xb)[:, :, tgt_idx]\n",
        "#             preds_scaled.append(yp.detach().cpu().numpy())\n",
        "#     preds_scaled = np.concatenate(preds_scaled, axis=0)\n",
        "\n",
        "#     preds_raw = scaler.inverse_transform(preds_scaled.reshape(-1, 1)).ravel()\n",
        "#     truth_raw = scaler.inverse_transform(Yte.reshape(-1, 1)).ravel()\n",
        "\n",
        "#     mae = np.mean(np.abs(preds_raw - truth_raw))\n",
        "#     rmse = np.sqrt(np.mean((preds_raw - truth_raw)**2))\n",
        "#     mbe = np.mean(preds_raw - truth_raw)\n",
        "\n",
        "#     # === ACI metrics ===\n",
        "#     coverage, miw, crps, winkler = run_ACI(preds_raw, truth_raw)\n",
        "\n",
        "#     return mae, rmse, mbe, coverage, miw, crps, winkler\n",
        "\n",
        "\n",
        "# # --- Run search ---\n",
        "# results = []\n",
        "# for combo in all_combos:\n",
        "#     try:\n",
        "#         mae, rmse, mbe, coverage, miw, crps, winkler = train_eval_patchtst(combo, train_set, test_set, scaler)\n",
        "#         results.append({\n",
        "#             \"SEQ_LEN\": combo[0], \"BATCH_SIZE\": combo[1], \"LR\": combo[2],\n",
        "#             \"D_MODEL\": combo[3], \"N_HEADS\": combo[4], \"PATCH_LEN\": combo[5],\n",
        "#             \"STRIDE\": combo[6], \"E_LAYERS\": combo[7],\n",
        "#             \"MAE\": mae, \"RMSE\": rmse, \"MBE\": mbe,\n",
        "#             \"Coverage%\": coverage, \"MIW\": miw, \"CRPS\": crps, \"Winkler\": winkler\n",
        "#         })\n",
        "#         print(f\"Done {combo} → RMSE={rmse:.3f}, Coverage={coverage:.1f}%\")\n",
        "#     except Exception as e:\n",
        "#         print(\"Failed:\", combo, \"error:\", str(e))\n",
        "\n",
        "# df_search = pd.DataFrame(results).sort_values(\"Coverage%\", ascending=False)\n",
        "# print(df_search.head(10))\n"
      ],
      "metadata": {
        "id": "p_YtrAu7fYsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # import os\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # === Function to save forecasts ===\n",
        "# def save_forecasts(truth_orig, preds_orig, test_set, model_name, filename):\n",
        "#     # Ensure save folder exists in Google Drive\n",
        "#     save_dir = \"/content/drive/MyDrive/Colab Notebooks/Forecasts\"\n",
        "#     os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "#     # Build full output path\n",
        "#     out_path = os.path.join(save_dir, filename)\n",
        "\n",
        "#     # Align lengths\n",
        "#     n = min(len(truth_orig), len(preds_orig), len(test_set.index))\n",
        "\n",
        "#     # Build dataframe\n",
        "#     df = pd.DataFrame({\n",
        "#         \"datetime\": pd.to_datetime(test_set.index[:n]),\n",
        "#         \"actual\": np.asarray(truth_orig).reshape(-1)[:n],\n",
        "#         \"forecast\": np.asarray(preds_orig).reshape(-1)[:n],\n",
        "#         \"model\": model_name\n",
        "#     })\n",
        "\n",
        "#     # Save to CSV\n",
        "#     df.to_csv(out_path, index=False)\n",
        "#     print(f\"[{model_name}] CSV saved to: {out_path}\")\n",
        "#     return df.head()\n",
        "\n",
        "# # === Example: Save Informer results ===\n",
        "# save_forecasts(\n",
        "#     truth_raw,      # your ground truth (kW)\n",
        "#     preds_raw,      # your model forecasts (kW)\n",
        "#     test_set,                  # DataFrame with datetime index\n",
        "#     \"PatchTST\",                # model name\n",
        "#     \"preds_PatchTST2.csv\"       # file name in Drive\n",
        "# )\n"
      ],
      "metadata": {
        "id": "1dD7iPXxpk8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "\n",
        "# results = []      # <--- reset before the loop\n",
        "# corrected = {}    # <--- reset too, if you’re saving corrected DataFrames\n",
        "\n",
        "# # --- Paths ---\n",
        "# base = \"/content/drive/MyDrive/Colab Notebooks/Forecasts\"\n",
        "# files = { \"Autoformer\": os.path.join(base, \"preds_Autoformer.csv\"),\n",
        "#          \"Informer\": os.path.join(base, \"preds_informer.csv\"),\n",
        "#           \"FEDformer\": os.path.join(base, \"preds_FEDformer.csv\"),\n",
        "#           \"PatchTST\": os.path.join(base, \"preds_PatchTST2.csv\"),\n",
        "#           \"DLinear\": os.path.join(base, \"preds_linear.csv\"), }\n",
        "\n",
        "# for name, path in files.items():\n",
        "#     df = pd.read_csv(path, parse_dates=[\"datetime\"])\n",
        "#     df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
        "\n",
        "#     # Rule 1: if actual[t] == 0 → forecast[t+1] = 0\n",
        "#     zero_idx = df.index[df[\"actual\"] == 0] + 1\n",
        "#     zero_idx = zero_idx[zero_idx < len(df)]\n",
        "#     df.loc[zero_idx, \"forecast\"] = 0.0\n",
        "\n",
        "#     # Rule 2: clip negatives\n",
        "#     df[\"forecast\"] = df[\"forecast\"].clip(lower=0)\n",
        "\n",
        "#     # Store corrected DF\n",
        "#     corrected[name] = df.copy()\n",
        "\n",
        "#     # Metrics\n",
        "#     mae  = mean_absolute_error(df[\"actual\"], df[\"forecast\"])\n",
        "#     rmse = np.sqrt(mean_squared_error(df[\"actual\"], df[\"forecast\"]))\n",
        "#     mbe  = (df[\"forecast\"] - df[\"actual\"]).mean()\n",
        "\n",
        "#     results.append({\n",
        "#         \"Model\": name,\n",
        "#         \"MAE (kW)\": mae,\n",
        "#         \"RMSE (kW)\": rmse,\n",
        "#         \"MBE (kW)\": mbe,\n",
        "#         \"MAE (% of 5kW peak)\": mae/5*100,\n",
        "#         \"RMSE (% of 5kW peak)\": rmse/5*100,\n",
        "#         \"MBE (% of 5kW peak)\": mbe/5*100,\n",
        "#     })\n",
        "\n",
        "# metrics_df = pd.DataFrame(results)\n",
        "# print(metrics_df.round(4))\n"
      ],
      "metadata": {
        "id": "BOtWZaULr3NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # === Extract PatchTST series for ACI ===\n",
        "# df_patch = corrected[\"PatchTST\"].copy()\n",
        "\n",
        "\n",
        "# # These are the actuals and forecasts after your rules (zero clipping etc.)\n",
        "# y_check_act = df_patch[\"actual\"].values    # ground truth\n",
        "# yhat_act    = df_patch[\"forecast\"].values  # point forecasts"
      ],
      "metadata": {
        "id": "eogDviF2RpIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set.shape, test_set[1:2].index, test_set[-1:].index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ulf6wJ2UufO",
        "outputId": "1b1ed1f6-d38c-4982-c000-fa0095cf1883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8761, 7) DatetimeIndex(['2018-02-01'], dtype='datetime64[ns]', name='datetime', freq=None) DatetimeIndex(['2019-01-31 23:00:00'], dtype='datetime64[ns]', name='datetime', freq=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_check_act_ACI = np.squeeze(y_check_act)\n",
        "y_uppers_ACI = np.squeeze(y_uppers_mamba_ACI)\n",
        "y_lowers_ACI = np.squeeze(y_lowers_mamba_ACI)\n",
        "yhat_act_stacked_ACI = np.squeeze(yhat_act)\n",
        "y_check_act_ACI = np.squeeze(y_check_act_ACI)\n",
        "y_uppers_ACI = np.squeeze(y_uppers_ACI)\n",
        "y_lowers_ACI = np.squeeze(y_lowers_ACI)\n",
        "yhat_act_stacked_ACI = np.squeeze(yhat_act_stacked_ACI)\n",
        "acp_ACI = pd.DataFrame([y_check_act_ACI,y_uppers_ACI,y_lowers_ACI]).T\n",
        "acp_ACI.columns = ['Actual', 'upper', 'lower']\n",
        "acp_ACI.index = test_set[48::].index"
      ],
      "metadata": {
        "id": "vWJ6pIKVU3Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = pd.to_datetime('2018-02-05 00:00:00')\n",
        "end_date = start_date + pd.Timedelta(hours=22)\n",
        "acp1 = acp_ACI[start_date:end_date]\n",
        "\n",
        "\n",
        "start_date = pd.to_datetime('2018-05-28 00:00:00')\n",
        "end_date = start_date + pd.Timedelta(hours=22)\n",
        "acp2 = acp_ACI[start_date:end_date]\n",
        "\n",
        "\n",
        "start_date = pd.to_datetime('2018-08-02 00:00:00')\n",
        "end_date = start_date + pd.Timedelta(hours=22)\n",
        "acp3 = acp_ACI[start_date:end_date]\n",
        "\n",
        "\n",
        "\n",
        "start_date = pd.to_datetime('2018-12-21 00:00:00')\n",
        "end_date = start_date + pd.Timedelta(hours=22)\n",
        "acp4 = acp_ACI[start_date:end_date]"
      ],
      "metadata": {
        "id": "eb0u0hu3VTfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "#Four days plot\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=\"Time (h)\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Time (h)\", row=1, col=2)\n",
        "fig.update_xaxes(title_text=\"Time (h)\", row=2, col=1)\n",
        "fig.update_xaxes(title_text=\"Time (h)\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Power (MW)\", row=1, col=1, nticks=6)\n",
        "fig.update_yaxes(title_text=\"Power (MW)\", row=1, col=2,nticks=6)\n",
        "fig.update_yaxes(title_text=\"Power (MW)\", row=2, col=1, nticks=6)\n",
        "fig.update_yaxes(title_text=\"Power (MW)\", row=2, col=2,nticks=6)\n",
        "\n",
        "# Updating the font size of x-axis and y-axis titles\n",
        "fig.update_xaxes(title_font=dict(size=24), row='all', col='all')\n",
        "fig.update_yaxes(title_font=dict(size=24), row='all', col='all')\n",
        "\n",
        "# Updating the font size of the axis tick labels\n",
        "fig.update_xaxes(tickfont=dict(size=24), row='all', col='all')\n",
        "fig.update_yaxes(tickfont=dict(size=24), row='all', col='all')\n",
        "\n",
        "# Updating the layout for the legend, title, and overall font\n",
        "fig.update_layout(\n",
        "    legend=dict(font=dict(size=24)),\n",
        "    title=dict(font=dict(size=24)),\n",
        "    font=dict(size=24)\n",
        ")\n",
        "\n",
        "\n",
        "fig.append_trace(go.Scatter(x= acp1.index.to_pydatetime(), y = acp1['Actual'],\n",
        "    name = 'Actual', legendgroup = '1', line=dict(color='blue', dash='dash'),\n",
        "    mode='lines+markers'), row=1, col=1)\n",
        "\n",
        "fig.append_trace(go.Scatter(name='PatchTST ACI', x=acp1.index, y=acp1['upper'],\n",
        "    mode='lines+markers', marker=dict(symbol='star'), line=dict(color='red', width=1),\n",
        "    legendgroup = '2'), row=1, col=1)\n",
        "\n",
        "fig.append_trace(go.Scatter(name='Lower Bound ACI', x=acp1.index, y=acp1['lower'],\n",
        "    line=dict(color='red', width=1), mode='lines+markers', showlegend=False,\n",
        "    marker=dict(symbol='star'), legendgroup = '2'), row=1, col=1)\n",
        "\n",
        "# Second subplot - hide duplicate legend entries\n",
        "fig.append_trace(go.Scatter(x= acp2.index.to_pydatetime(), y = acp2['Actual'],\n",
        "    name = 'Actual', legendgroup = '1', line=dict(color='blue', dash='dash'),\n",
        "    mode='lines+markers', showlegend=False), row=1, col=2)\n",
        "\n",
        "fig.append_trace(go.Scatter(name='PatchTST ACI', x=acp2.index, y=acp2['upper'],\n",
        "    mode='lines+markers', marker=dict(symbol='star'), line=dict(color='red', width=1),\n",
        "    legendgroup = '2', showlegend=False), row=1, col=2)\n",
        "\n",
        "fig.append_trace(go.Scatter(name='Lower Bound ACI', x=acp2.index, y=acp2['lower'],\n",
        "    line=dict(color='red', width=1), mode='lines+markers', showlegend=False,\n",
        "    marker=dict(symbol='star'), legendgroup = '2'), row=1, col=2)\n",
        "\n",
        "# Third subplot - hide duplicate legend entries\n",
        "fig.append_trace(go.Scatter(x= acp3.index.to_pydatetime(), y = acp3['Actual'],\n",
        "    name = 'Actual', legendgroup = '1', line=dict(color='blue', dash='dash'),\n",
        "    mode='lines+markers', showlegend=False), row=2, col=1)\n",
        "\n",
        "fig.append_trace(go.Scatter(name='PatchTST ACI', x=acp3.index, y=acp3['upper'],\n",
        "    mode='lines+markers', marker=dict(symbol='star'), line=dict(color='red', width=1),\n",
        "    legendgroup = '2', showlegend=False), row=2, col=1)\n",
        "\n",
        "fig.append_trace(go.Scatter(name='Lower Bound ACI', x=acp3.index, y=acp3['lower'],\n",
        "    line=dict(color='red', width=1), mode='lines+markers', showlegend=False,\n",
        "    marker=dict(symbol='star'), legendgroup = '2'), row=2, col=1)\n",
        "\n",
        "# Fourth subplot - hide duplicate legend entries\n",
        "fig.append_trace(go.Scatter(x= acp4.index.to_pydatetime(), y = acp4['Actual'],\n",
        "    name = 'Actual', legendgroup = '1', line=dict(color='blue', dash='dash'),\n",
        "    mode='lines+markers', showlegend=False), row=2, col=2)\n",
        "\n",
        "fig.append_trace(go.Scatter(name='PatchTST ACI', x=acp4.index, y=acp4['upper'],\n",
        "    mode='lines+markers', marker=dict(symbol='star'), line=dict(color='red', width=1),\n",
        "    legendgroup = '2', showlegend=False), row=2, col=2)\n",
        "\n",
        "fig.append_trace(go.Scatter(name='Lower Bound ACI', x=acp4.index, y=acp4['lower'],\n",
        "    line=dict(color='red', width=1), mode='lines+markers', showlegend=False,\n",
        "    marker=dict(symbol='star'), legendgroup = '2'), row=2, col=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(fig.layout.annotations)):\n",
        "    fig.layout.annotations[i].font.size = 24\n",
        "\n",
        "fig.update_layout(\n",
        "    height=1200,\n",
        "    width=2000,  # Consider increasing this if it's feasible\n",
        "    template='simple_white',\n",
        "    title={\n",
        "        'text': \"Interval Forecast Performance\",\n",
        "        'y':0.99,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'\n",
        "    },\n",
        "    font=dict(size=20, color=\"Black\"),\n",
        "    title_font=dict(size=24, color=\"Black\"),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",  # Horizontal layout\n",
        "        yanchor=\"bottom\",  # Anchored at the bottom\n",
        "        y=-0.2,  # Adjust this value to move the legend down\n",
        "        xanchor=\"center\",  # Center anchor\n",
        "        x=0.5  # Centered horizontally\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "i4Ho3HVDVi_N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0d47fb0-b839-4825-b795-b4e419d3e010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"441af25e-4a1b-481e-a0c6-164c4c028e5f\" class=\"plotly-graph-div\" style=\"height:1200px; width:2000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"441af25e-4a1b-481e-a0c6-164c4c028e5f\")) {                    Plotly.newPlot(                        \"441af25e-4a1b-481e-a0c6-164c4c028e5f\",                        [{\"legendgroup\":\"1\",\"line\":{\"color\":\"blue\",\"dash\":\"dash\"},\"mode\":\"lines+markers\",\"name\":\"Actual\",\"x\":[\"2018-02-05T00:00:00\",\"2018-02-05T01:00:00\",\"2018-02-05T02:00:00\",\"2018-02-05T03:00:00\",\"2018-02-05T04:00:00\",\"2018-02-05T05:00:00\",\"2018-02-05T06:00:00\",\"2018-02-05T07:00:00\",\"2018-02-05T08:00:00\",\"2018-02-05T09:00:00\",\"2018-02-05T10:00:00\",\"2018-02-05T11:00:00\",\"2018-02-05T12:00:00\",\"2018-02-05T13:00:00\",\"2018-02-05T14:00:00\",\"2018-02-05T15:00:00\",\"2018-02-05T16:00:00\",\"2018-02-05T17:00:00\",\"2018-02-05T18:00:00\",\"2018-02-05T19:00:00\",\"2018-02-05T20:00:00\",\"2018-02-05T21:00:00\",\"2018-02-05T22:00:00\"],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0010812000837177038,0.1166548877954483,0.310981810092926,0.4082939624786377,0.22341540455818176,1.2762609720230103,1.5241912603378296,1.0211237668991089,0.46412229537963867,0.05339843034744263,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"legendgroup\":\"2\",\"line\":{\"color\":\"red\",\"width\":1},\"marker\":{\"symbol\":\"star\"},\"mode\":\"lines+markers\",\"name\":\"PatchTST ACI\",\"x\":[\"2018-02-05T00:00:00\",\"2018-02-05T01:00:00\",\"2018-02-05T02:00:00\",\"2018-02-05T03:00:00\",\"2018-02-05T04:00:00\",\"2018-02-05T05:00:00\",\"2018-02-05T06:00:00\",\"2018-02-05T07:00:00\",\"2018-02-05T08:00:00\",\"2018-02-05T09:00:00\",\"2018-02-05T10:00:00\",\"2018-02-05T11:00:00\",\"2018-02-05T12:00:00\",\"2018-02-05T13:00:00\",\"2018-02-05T14:00:00\",\"2018-02-05T15:00:00\",\"2018-02-05T16:00:00\",\"2018-02-05T17:00:00\",\"2018-02-05T18:00:00\",\"2018-02-05T19:00:00\",\"2018-02-05T20:00:00\",\"2018-02-05T21:00:00\",\"2018-02-05T22:00:00\"],\"y\":[0.4634629487991333,0.4804871678352356,0.4868578314781189,0.49270445108413696,0.5082104802131653,0.5077472925186157,0.5179692506790161,0.5127846002578735,0.5206127762794495,0.5988426208496094,0.8250201940536499,0.8779460787773132,0.5936633944511414,1.531364917755127,1.4444453716278076,1.115041971206665,0.60689377784729,0.4876520037651062,0.4463827908039093,0.4053489863872528,0.3894071578979492,0.39294227957725525,0.4004102349281311],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"legendgroup\":\"2\",\"line\":{\"color\":\"red\",\"width\":1},\"marker\":{\"symbol\":\"star\"},\"mode\":\"lines+markers\",\"name\":\"Lower Bound ACI\",\"showlegend\":false,\"x\":[\"2018-02-05T00:00:00\",\"2018-02-05T01:00:00\",\"2018-02-05T02:00:00\",\"2018-02-05T03:00:00\",\"2018-02-05T04:00:00\",\"2018-02-05T05:00:00\",\"2018-02-05T06:00:00\",\"2018-02-05T07:00:00\",\"2018-02-05T08:00:00\",\"2018-02-05T09:00:00\",\"2018-02-05T10:00:00\",\"2018-02-05T11:00:00\",\"2018-02-05T12:00:00\",\"2018-02-05T13:00:00\",\"2018-02-05T14:00:00\",\"2018-02-05T15:00:00\",\"2018-02-05T16:00:00\",\"2018-02-05T17:00:00\",\"2018-02-05T18:00:00\",\"2018-02-05T19:00:00\",\"2018-02-05T20:00:00\",\"2018-02-05T21:00:00\",\"2018-02-05T22:00:00\"],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012670546770095825,0.07272857427597046,0.0,0.6890190243721008,0.6111024022102356,0.28875070810317993,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"legendgroup\":\"1\",\"line\":{\"color\":\"blue\",\"dash\":\"dash\"},\"mode\":\"lines+markers\",\"name\":\"Actual\",\"showlegend\":false,\"x\":[\"2018-05-28T00:00:00\",\"2018-05-28T01:00:00\",\"2018-05-28T02:00:00\",\"2018-05-28T03:00:00\",\"2018-05-28T04:00:00\",\"2018-05-28T05:00:00\",\"2018-05-28T06:00:00\",\"2018-05-28T07:00:00\",\"2018-05-28T08:00:00\",\"2018-05-28T09:00:00\",\"2018-05-28T10:00:00\",\"2018-05-28T11:00:00\",\"2018-05-28T12:00:00\",\"2018-05-28T13:00:00\",\"2018-05-28T14:00:00\",\"2018-05-28T15:00:00\",\"2018-05-28T16:00:00\",\"2018-05-28T17:00:00\",\"2018-05-28T18:00:00\",\"2018-05-28T19:00:00\",\"2018-05-28T20:00:00\",\"2018-05-28T21:00:00\",\"2018-05-28T22:00:00\"],\"y\":[0.0,0.0,0.0,0.0,0.0009025183389894664,0.13833501935005188,0.4894527792930603,0.9281182885169983,2.327958583831787,3.182354688644409,3.7924468517303467,4.213440895080566,3.9429492950439453,3.547210693359375,3.4484505653381348,2.8004374504089355,1.9180182218551636,0.9516553282737732,0.40067407488822937,0.1939929723739624,0.03264399617910385,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"legendgroup\":\"2\",\"line\":{\"color\":\"red\",\"width\":1},\"marker\":{\"symbol\":\"star\"},\"mode\":\"lines+markers\",\"name\":\"PatchTST ACI\",\"showlegend\":false,\"x\":[\"2018-05-28T00:00:00\",\"2018-05-28T01:00:00\",\"2018-05-28T02:00:00\",\"2018-05-28T03:00:00\",\"2018-05-28T04:00:00\",\"2018-05-28T05:00:00\",\"2018-05-28T06:00:00\",\"2018-05-28T07:00:00\",\"2018-05-28T08:00:00\",\"2018-05-28T09:00:00\",\"2018-05-28T10:00:00\",\"2018-05-28T11:00:00\",\"2018-05-28T12:00:00\",\"2018-05-28T13:00:00\",\"2018-05-28T14:00:00\",\"2018-05-28T15:00:00\",\"2018-05-28T16:00:00\",\"2018-05-28T17:00:00\",\"2018-05-28T18:00:00\",\"2018-05-28T19:00:00\",\"2018-05-28T20:00:00\",\"2018-05-28T21:00:00\",\"2018-05-28T22:00:00\"],\"y\":[0.5916513800621033,0.6055910587310791,0.5791277289390564,0.5629932284355164,0.5557512044906616,0.5988749861717224,0.7886815071105957,1.470633625984192,2.2952632904052734,3.330620765686035,3.8689048290252686,4.03707218170166,4.574240207672119,3.531784772872925,3.1956191062927246,2.8742918968200684,2.2037558555603027,1.4556750059127808,0.8258945941925049,0.7411558628082275,0.6160122156143188,0.5206540822982788,0.5219283699989319],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"legendgroup\":\"2\",\"line\":{\"color\":\"red\",\"width\":1},\"marker\":{\"symbol\":\"star\"},\"mode\":\"lines+markers\",\"name\":\"Lower Bound ACI\",\"showlegend\":false,\"x\":[\"2018-05-28T00:00:00\",\"2018-05-28T01:00:00\",\"2018-05-28T02:00:00\",\"2018-05-28T03:00:00\",\"2018-05-28T04:00:00\",\"2018-05-28T05:00:00\",\"2018-05-28T06:00:00\",\"2018-05-28T07:00:00\",\"2018-05-28T08:00:00\",\"2018-05-28T09:00:00\",\"2018-05-28T10:00:00\",\"2018-05-28T11:00:00\",\"2018-05-28T12:00:00\",\"2018-05-28T13:00:00\",\"2018-05-28T14:00:00\",\"2018-05-28T15:00:00\",\"2018-05-28T16:00:00\",\"2018-05-28T17:00:00\",\"2018-05-28T18:00:00\",\"2018-05-28T19:00:00\",\"2018-05-28T20:00:00\",\"2018-05-28T21:00:00\",\"2018-05-28T22:00:00\"],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4222075939178467,1.2567825317382812,2.2235283851623535,2.767625093460083,2.943885326385498,3.430321216583252,2.3930137157440186,2.0490598678588867,1.7277326583862305,1.0629655122756958,0.32154130935668945,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"legendgroup\":\"1\",\"line\":{\"color\":\"blue\",\"dash\":\"dash\"},\"mode\":\"lines+markers\",\"name\":\"Actual\",\"showlegend\":false,\"x\":[\"2018-08-02T00:00:00\",\"2018-08-02T01:00:00\",\"2018-08-02T02:00:00\",\"2018-08-02T03:00:00\",\"2018-08-02T04:00:00\",\"2018-08-02T05:00:00\",\"2018-08-02T06:00:00\",\"2018-08-02T07:00:00\",\"2018-08-02T08:00:00\",\"2018-08-02T09:00:00\",\"2018-08-02T10:00:00\",\"2018-08-02T11:00:00\",\"2018-08-02T12:00:00\",\"2018-08-02T13:00:00\",\"2018-08-02T14:00:00\",\"2018-08-02T15:00:00\",\"2018-08-02T16:00:00\",\"2018-08-02T17:00:00\",\"2018-08-02T18:00:00\",\"2018-08-02T19:00:00\",\"2018-08-02T20:00:00\",\"2018-08-02T21:00:00\",\"2018-08-02T22:00:00\"],\"y\":[0.0,0.0,0.0,0.0,0.0,0.007679922040551901,0.18314605951309204,0.591817319393158,1.955378770828247,2.6728811264038086,3.2867250442504883,3.7533936500549316,3.806462049484253,2.5327603816986084,3.0247442722320557,2.256976366043091,1.7215287685394287,0.7162995338439941,0.3415418267250061,0.1436568647623062,0.015358073636889458,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"legendgroup\":\"2\",\"line\":{\"color\":\"red\",\"width\":1},\"marker\":{\"symbol\":\"star\"},\"mode\":\"lines+markers\",\"name\":\"PatchTST ACI\",\"showlegend\":false,\"x\":[\"2018-08-02T00:00:00\",\"2018-08-02T01:00:00\",\"2018-08-02T02:00:00\",\"2018-08-02T03:00:00\",\"2018-08-02T04:00:00\",\"2018-08-02T05:00:00\",\"2018-08-02T06:00:00\",\"2018-08-02T07:00:00\",\"2018-08-02T08:00:00\",\"2018-08-02T09:00:00\",\"2018-08-02T10:00:00\",\"2018-08-02T11:00:00\",\"2018-08-02T12:00:00\",\"2018-08-02T13:00:00\",\"2018-08-02T14:00:00\",\"2018-08-02T15:00:00\",\"2018-08-02T16:00:00\",\"2018-08-02T17:00:00\",\"2018-08-02T18:00:00\",\"2018-08-02T19:00:00\",\"2018-08-02T20:00:00\",\"2018-08-02T21:00:00\",\"2018-08-02T22:00:00\"],\"y\":[0.5277464389801025,0.5179510116577148,0.49850061535835266,0.4770641028881073,0.46136802434921265,0.4882211983203888,0.5731895565986633,0.9027212262153625,1.7298097610473633,3.0164449214935303,3.4780077934265137,3.874751567840576,3.952096462249756,3.7580347061157227,2.3893070220947266,2.7384934425354004,2.099513530731201,1.409093976020813,0.7495114803314209,0.6738763451576233,0.46434786915779114,0.4198886752128601,0.46507298946380615],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"legendgroup\":\"2\",\"line\":{\"color\":\"red\",\"width\":1},\"marker\":{\"symbol\":\"star\"},\"mode\":\"lines+markers\",\"name\":\"Lower Bound ACI\",\"showlegend\":false,\"x\":[\"2018-08-02T00:00:00\",\"2018-08-02T01:00:00\",\"2018-08-02T02:00:00\",\"2018-08-02T03:00:00\",\"2018-08-02T04:00:00\",\"2018-08-02T05:00:00\",\"2018-08-02T06:00:00\",\"2018-08-02T07:00:00\",\"2018-08-02T08:00:00\",\"2018-08-02T09:00:00\",\"2018-08-02T10:00:00\",\"2018-08-02T11:00:00\",\"2018-08-02T12:00:00\",\"2018-08-02T13:00:00\",\"2018-08-02T14:00:00\",\"2018-08-02T15:00:00\",\"2018-08-02T16:00:00\",\"2018-08-02T17:00:00\",\"2018-08-02T18:00:00\",\"2018-08-02T19:00:00\",\"2018-08-02T20:00:00\",\"2018-08-02T21:00:00\",\"2018-08-02T22:00:00\"],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023363173007965088,0.8595592975616455,2.0922605991363525,2.559845447540283,2.9663453102111816,3.0529651641845703,2.8665714263916016,1.4485313892364502,1.747976303100586,1.1155099868774414,0.43294814229011536,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"legendgroup\":\"1\",\"line\":{\"color\":\"blue\",\"dash\":\"dash\"},\"mode\":\"lines+markers\",\"name\":\"Actual\",\"showlegend\":false,\"x\":[\"2018-12-21T00:00:00\",\"2018-12-21T01:00:00\",\"2018-12-21T02:00:00\",\"2018-12-21T03:00:00\",\"2018-12-21T04:00:00\",\"2018-12-21T05:00:00\",\"2018-12-21T06:00:00\",\"2018-12-21T07:00:00\",\"2018-12-21T08:00:00\",\"2018-12-21T09:00:00\",\"2018-12-21T10:00:00\",\"2018-12-21T11:00:00\",\"2018-12-21T12:00:00\",\"2018-12-21T13:00:00\",\"2018-12-21T14:00:00\",\"2018-12-21T15:00:00\",\"2018-12-21T16:00:00\",\"2018-12-21T17:00:00\",\"2018-12-21T18:00:00\",\"2018-12-21T19:00:00\",\"2018-12-21T20:00:00\",\"2018-12-21T21:00:00\",\"2018-12-21T22:00:00\"],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03370299190282822,0.1622338593006134,0.273563951253891,0.37318557500839233,0.3446274697780609,0.343379408121109,0.12147055566310883,0.003156637540087104,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"legendgroup\":\"2\",\"line\":{\"color\":\"red\",\"width\":1},\"marker\":{\"symbol\":\"star\"},\"mode\":\"lines+markers\",\"name\":\"PatchTST ACI\",\"showlegend\":false,\"x\":[\"2018-12-21T00:00:00\",\"2018-12-21T01:00:00\",\"2018-12-21T02:00:00\",\"2018-12-21T03:00:00\",\"2018-12-21T04:00:00\",\"2018-12-21T05:00:00\",\"2018-12-21T06:00:00\",\"2018-12-21T07:00:00\",\"2018-12-21T08:00:00\",\"2018-12-21T09:00:00\",\"2018-12-21T10:00:00\",\"2018-12-21T11:00:00\",\"2018-12-21T12:00:00\",\"2018-12-21T13:00:00\",\"2018-12-21T14:00:00\",\"2018-12-21T15:00:00\",\"2018-12-21T16:00:00\",\"2018-12-21T17:00:00\",\"2018-12-21T18:00:00\",\"2018-12-21T19:00:00\",\"2018-12-21T20:00:00\",\"2018-12-21T21:00:00\",\"2018-12-21T22:00:00\"],\"y\":[0.475221186876297,0.48370516300201416,0.48071637749671936,0.48864471912384033,0.4718928337097168,0.48929688334465027,0.5035490393638611,0.5060548782348633,0.5137196779251099,0.5239784121513367,0.6422427892684937,0.7041157484054565,0.7685974836349487,0.5842258930206299,0.5303038954734802,0.4221644699573517,0.40101706981658936,0.3941032588481903,0.3724324405193329,0.3494932949542999,0.34907662868499756,0.3511480391025543,0.3432731032371521],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"legendgroup\":\"2\",\"line\":{\"color\":\"red\",\"width\":1},\"marker\":{\"symbol\":\"star\"},\"mode\":\"lines+markers\",\"name\":\"Lower Bound ACI\",\"showlegend\":false,\"x\":[\"2018-12-21T00:00:00\",\"2018-12-21T01:00:00\",\"2018-12-21T02:00:00\",\"2018-12-21T03:00:00\",\"2018-12-21T04:00:00\",\"2018-12-21T05:00:00\",\"2018-12-21T06:00:00\",\"2018-12-21T07:00:00\",\"2018-12-21T08:00:00\",\"2018-12-21T09:00:00\",\"2018-12-21T10:00:00\",\"2018-12-21T11:00:00\",\"2018-12-21T12:00:00\",\"2018-12-21T13:00:00\",\"2018-12-21T14:00:00\",\"2018-12-21T15:00:00\",\"2018-12-21T16:00:00\",\"2018-12-21T17:00:00\",\"2018-12-21T18:00:00\",\"2018-12-21T19:00:00\",\"2018-12-21T20:00:00\",\"2018-12-21T21:00:00\",\"2018-12-21T22:00:00\"],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02766522765159607,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Time (h)\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.575,1.0],\"title\":{\"text\":\"Power (MW)\"},\"nticks\":6},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Time (h)\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.575,1.0],\"title\":{\"text\":\"Power (MW)\"},\"nticks\":6},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Time (h)\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.425],\"title\":{\"text\":\"Power (MW)\"},\"nticks\":6},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Time (h)\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.425],\"title\":{\"text\":\"Power (MW)\"},\"nticks\":6},\"legend\":{\"font\":{\"size\":24},\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":-0.2,\"xanchor\":\"center\",\"x\":0.5},\"title\":{\"font\":{\"size\":24,\"color\":\"Black\"},\"text\":\"Interval Forecast Performance\",\"y\":0.99,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"font\":{\"size\":20,\"color\":\"Black\"},\"height\":1200,\"width\":2000},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('441af25e-4a1b-481e-a0c6-164c4c028e5f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-OVTOZtCmNI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}